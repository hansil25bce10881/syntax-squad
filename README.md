# syntax-squad
# ğŸš™ Offroad Semantic Scene Segmentation

### Duality AI â€“ GHR 2.0 Hackathon

## ğŸ“Œ Project Overview

This project named enviroNet.seg implements a **semantic scene segmentation model** for off-road autonomy using synthetic desert environments generated from Duality AIâ€™s Falcon digital twin platform.

The goal is to train a model that accurately labels every pixel in an image into terrain/object classes (trees, bushes, rocks, sky, etc.) and generalizes well to **unseen desert environments**.

Semantic segmentation is critical for unmanned ground vehicles (UGVs) to perform obstacle avoidance and path planning.

---

## ğŸ¯ Objectives

* Train a robust semantic segmentation model on the provided dataset
* Evaluate performance on unseen test images
* Optimize accuracy and generalization
* Report **IoU score**, loss curves, and failure cases

---

## ğŸ—‚ Dataset

The dataset contains synthetic RGB images and pixel-wise ground-truth labels.

### Classes

| ID    | Class          |
| ----- | -------------- |
| 100   | Trees          |
| 200   | Lush Bushes    |
| 300   | Dry Grass      |
| 500   | Dry Bushes     |
| 550   | Ground Clutter |
| 600   | Flowers        |
| 700   | Logs           |
| 800   | Rocks          |
| 7100  | Landscape      |
| 10000 | Sky            |

Folder structure:

```
dataset/
 â”œâ”€â”€ Train/
 â”‚    â”œâ”€â”€ images/
 â”‚    â””â”€â”€ masks/
 â”œâ”€â”€ Val/
 â”‚    â”œâ”€â”€ images/
 â”‚    â””â”€â”€ masks/
 â””â”€â”€ testImages/
```


---

## ğŸ§  Model

You may use any semantic segmentation architecture (e.g., U-Net, DeepLabV3+, custom CNN).

This repository includes:

* `train.py` â€“ training script
* `test.py` â€“ evaluation on unseen images
* `config.yaml` â€“ model + hyperparameters
* `runs/` â€“ logs and checkpoints

---

## âš™ï¸ Environment Setup

### 1. Install Anaconda / Miniconda

Ensure Conda is installed.

### 2. Create Environment

Navigate to `ENV_SETUP/` and run:

**Windows**

```bash
setup_env.bat
```

**Mac / Linux**

Create and run `setup_env.sh` with equivalent commands.

This creates an environment named:

```bash
conda activate EDU
```

---

## â–¶ï¸ Training

Activate environment:

```bash
conda activate EDU
```

Start training:

```bash
python train.py
```

Outputs:

* Model checkpoints â†’ `runs/`
* Training logs
* Loss curves

---

## ğŸ§ª Testing (Unseen Environment)

Evaluate model robustness:

```bash
python test.py
```

This produces:

* Predicted masks
* IoU score
* Loss metrics

Use this as your **benchmark** for improvement.

---

## ğŸ“Š Evaluation Metrics

Primary metric:

* **IoU (Intersection over Union)** â€“ measures pixel-level accuracy

Additional analysis:

* Training / validation loss graphs
* Failure case visualization
* Class-wise performance

---

## ğŸ“ˆ Expected Deliverables

### âœ… Trained Model

* Model weights
* Training & inference scripts
* Configuration files

### âœ… Performance Report

* Final IoU score
* Loss curves
* Failure case analysis
* Optimization steps


Storytelling flow:

**Problem â†’ Fix â†’ Results â†’ Challenges â†’ Future Work**

---

## ğŸš€ Future Improvements

* Domain adaptation
* Self-supervised learning
* Data augmentation
* Class imbalance handling
* Lightweight models for faster inference

---

## ğŸ™Œ Acknowledgements

Duality AI Falcon Platform
GHR 2.0 Hackathon Team
